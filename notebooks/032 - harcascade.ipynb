{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(r\"C:\\Users\\aliay\\OneDrive\\Desktop\\py_test\\computer vision\\Github\\Computer_vision\\models\\haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(r\"C:\\Users\\aliay\\OneDrive\\Desktop\\py_test\\computer vision\\Github\\Computer_vision\\models\\haarcascade_eye_tree_eyeglasses.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>How to detect face </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    _, img = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Detect Face and Eye</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    _, img = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "        cv2.putText(img,\"Face\",(x,y-4),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),2)\n",
    "\n",
    "        eyes = eye_cascade.detectMultiScale(gray,2.3,4)\n",
    "        for (xx,yy,ww,hh) in eyes:\n",
    "            cv2.rectangle(img,(xx,yy),(xx+ww,yy+hh),(255,255,0),3)\n",
    "            cv2.putText(img,\"Eye\",(xx,yy-3),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,0),2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the Viola-Jones Algorithm for Real-Time Face Detection\n",
    "If you've ever wondered how real-time face detection works in cameras and social media apps, then you'll find the Viola-Jones algorithm fascinating. Let's break it down!\n",
    "\n",
    "What is the Viola-Jones Algorithm?\n",
    "The Viola-Jones algorithm is a robust and efficient method for object detection, particularly known for its application in face detection. It uses a combination of Haar-like features, integral images, AdaBoost, and a cascade classifier to achieve real-time performance.\n",
    "\n",
    "Step-by-Step Breakdown:\n",
    "1. Haar-like Features\n",
    "Haar-like features are used to identify patterns such as edges, lines, and rectangles by comparing pixel intensities. These features are computationally simple and efficient.\n",
    "\n",
    "2. Integral Image\n",
    "The integral image is a key optimization in the Viola-Jones algorithm. It allows the calculation of the sum of pixel values in any rectangular area in constant time, making the process much faster.\n",
    "\n",
    "3. AdaBoost\n",
    "AdaBoost is a machine learning technique that helps in selecting the most critical features and forming a strong classifier. It combines many weak classifiers (simple features) into a strong one.\n",
    "\n",
    "4. Cascade Classifier\n",
    "The cascade classifier improves detection speed by organizing the strong classifier into a series of stages. Each stage quickly rejects non-object regions, allowing more complex analysis for regions that pass through.\n",
    "\n",
    "How It Works:\n",
    "Training Phase:\n",
    "\n",
    "Collect a large set of positive (e.g., faces) and negative (e.g., non-faces) images.\n",
    "Extract Haar-like features from these images.\n",
    "Use AdaBoost to select the best features and train weak classifiers.\n",
    "Combine weak classifiers into a strong classifier and organize it into a cascade of stages.\n",
    "Detection Phase:\n",
    "\n",
    "Convert the input image to grayscale.\n",
    "Compute the integral image.\n",
    "Scan the image at multiple scales and positions using the cascade classifier.\n",
    "Quickly discard non-object regions and focus on promising areas.\n",
    "Regions that pass all stages are considered to contain the object (e.g., a face).\n",
    "Key Advantages:\n",
    "Real-Time Performance: The cascade structure allows for rapid rejection of non-object regions, making it suitable for real-time applications.\n",
    "Robustness: The combination of features and stages makes the algorithm robust to variations in lighting, pose, and facial expressions.\n",
    "Applications:\n",
    "Face Detection: Widely used in digital cameras, social media platforms, and security systems.\n",
    "Object Detection: Can be adapted for detecting other objects by training on relevant datasets.\n",
    "Conclusion:\n",
    "The Viola-Jones algorithm's blend of simplicity and efficiency has made it a cornerstone in the field of real-time face detection. Whether you're working on computer vision projects or just curious about the technology behind face detection, understanding Viola-Jones is a valuable step.\n",
    "\n",
    "For more details, you can refer to this comprehensive guide: The Viola-Jones Algorithm Explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
