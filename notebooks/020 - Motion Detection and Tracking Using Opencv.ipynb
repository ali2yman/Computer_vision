{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Our First Project in Motion Detection Using CV</b>\n",
    "\n",
    "1 - Frame Comparison:\n",
    "Objective: Detect motion by comparing consecutive frames.\n",
    "How: Calculate the difference between two frames.\n",
    "\n",
    "2 - Noise Reduction with Blurring:\n",
    "Objective: Eliminate unwanted details and light variations.\n",
    "How: Apply Gaussian blur to smooth out the differences.\n",
    "\n",
    "3 - Thresholding for Clarity:\n",
    "Objective: Enhance significant changes for easy detection.\n",
    "How: Set a threshold to create a clean binary image.\n",
    "\n",
    "4 - Dilating for Connectivity:\n",
    "Objective: Connect nearby changes for robust detection.\n",
    "How: Dilate the thresholded image to strengthen contours.\n",
    "\n",
    "5 - Contour Detection and Filtering:\n",
    "Objective: Identify meaningful shapes and eliminate noise.\n",
    "How: Find contours and filter based on area.\n",
    "\n",
    "6 - Rectangle Drawing for Visualization:\n",
    "Objective: Highlight detected motion on the frame.\n",
    "How: Draw rectangles around significant contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(r\"C:\\Users\\aliay\\OneDrive\\Desktop\\py_test\\computer vision\\dataset\\vtest.avi\")\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# fourcc >> for video codec XVID to make good compression (performance,quality)\n",
    "# 30 >> 30 frame per second \n",
    "fourcc =  cv2.VideoWriter_fourcc(*'mp4v') # *XVID\n",
    "out = cv2.VideoWriter(\"output.mp4\",fourcc,30,(frame_width,frame_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 768, 3)\n"
     ]
    }
   ],
   "source": [
    "ret,frame1 = cap.read()\n",
    "ret,frame2 = cap.read()\n",
    "print(frame1.shape)\n",
    "movement = \"No Movement\"  # Initialize movement variable outside the loop\n",
    "\n",
    "while cap.isOpened():\n",
    "    diff = cv2.absdiff(frame1,frame2)\n",
    "    gray = cv2.cvtColor(diff,cv2.COLOR_BGR2GRAY)\n",
    "    # 0 >>> to get the standerd devision based on kernal size automatically ,,The standard deviation (sigma) in the context of Gaussian blur is a measure of the spread or dispersion of the values in the Gaussian kernel. It affects the amount of smoothing applied to the image. A larger standard deviation results in a broader, more spread-out Gaussian curve,\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    _,thresh = cv2.threshold(blur,60,255,cv2.THRESH_BINARY)\n",
    "    dilated = cv2.dilate(thresh,None,iterations=10)\n",
    "    # (cv2.RETR_TREE) is used to retrieves all of the contours and reconstructs a full hierarchy of nested contours. The hierarchy is useful when you have contours within contours (for example, if one object is inside another).\n",
    "    # (cv2.CHAIN_APPROX_NONE) used means that all the boundary points of the contours will be stored in the output contours variable (contours). No approximation is made, and every point along the boundary is retained.\n",
    "    contours,_ = cv2.findContours(dilated,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    for contour in contours:\n",
    "        (x,y,w,h) = cv2.boundingRect(contour)\n",
    "\n",
    "        # should be bigger than 900 3shan y3ml 3lyha rectangle \n",
    "        if cv2.contourArea(contour) < 900 :\n",
    "            continue\n",
    "        cv2.rectangle(frame1,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        movement = \"Movement Detected\"\n",
    "\n",
    "        # (10,50) >> elpoint ely hatt7t 3ndha\n",
    "        # 1 >> font scale \n",
    "    cv2.putText(frame1, f\"Status: {movement}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "\n",
    "\n",
    "    image = cv2.resize(frame1,(1280,720))    \n",
    "    out.write(image)\n",
    "    cv2.imshow(\"motion detection\",frame1)\n",
    "\n",
    "    # what i did here to work in all frames in video l7d ma elvideo y5ls \n",
    "    frame1 = frame2\n",
    "    ret,frame2 = cap.read()\n",
    "\n",
    "    if cv2.waitKey(60) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "out.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
