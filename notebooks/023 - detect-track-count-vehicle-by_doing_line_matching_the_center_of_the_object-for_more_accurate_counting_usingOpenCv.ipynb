{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import os \n",
    "os.chdir(r\"C:\\Users\\aliay\\OneDrive\\Desktop\\py_test\\computer vision\\dataset\\34 -35 detect-track and count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = 80 \n",
    "hh = 80\n",
    "offset = 6\n",
    "y1 = 550\n",
    "delay = 60         #FPS to video \n",
    "detect = []\n",
    "carros = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the center of the object\n",
    "def object_center(x,y,w,h):\n",
    "    x1 = int(w/2)\n",
    "    y1 = int(h/2)\n",
    "    cx = x + x1\n",
    "    cy = y + y1\n",
    "    return cx,cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of cars detected : 1\n",
      "No. of cars detected : 2\n",
      "No. of cars detected : 3\n",
      "No. of cars detected : 4\n",
      "No. of cars detected : 5\n",
      "No. of cars detected : 6\n",
      "No. of cars detected : 7\n",
      "No. of cars detected : 8\n",
      "No. of cars detected : 9\n",
      "No. of cars detected : 10\n",
      "No. of cars detected : 11\n",
      "No. of cars detected : 12\n",
      "No. of cars detected : 13\n",
      "No. of cars detected : 14\n",
      "No. of cars detected : 15\n",
      "No. of cars detected : 16\n",
      "No. of cars detected : 17\n",
      "No. of cars detected : 18\n",
      "No. of cars detected : 19\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "# defult values >>> \n",
    "# history=500,        # Number of frames used to build the model\n",
    "# varThreshold=16,    # Threshold on the squared Mahalanobis distance to decide whether it is well-described by the background model\n",
    "# detectShadows=True   # If True, the algorithm detects and marks shadows, otherwise not\n",
    "BGS = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    ret,frame1 = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    # blurring to reduce the noise \n",
    "    blur = cv2.GaussianBlur(gray,(3,3),5)\n",
    "    img_sub = BGS.apply(blur)\n",
    "    # dilation to fill the gaps in objects\n",
    "    dilat = cv2.dilate(img_sub,np.ones((5,5)))\n",
    "    # make a line >> to detect the object ely hy3dy mn 3la el line da \n",
    "    cv2.line(frame1,(25,y1),(1200,y1),(176,130,40),2) \n",
    "\n",
    "    # Use cv2.CHAIN_APPROX_SIMPLE if you want a simplified representation of the contour, where straight segments are approximated by their end points.\n",
    "    # Use cv2.CHAIN_APPROX_NONE if you want to retain all the contour points without any approximation.\n",
    "    contor,h = cv2.findContours(dilat,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for(i,c) in enumerate(contor):\n",
    "        (x,y,w,h) = cv2.boundingRect(c)\n",
    "        \n",
    "        # 3shan y3ml detect b rectangle 3la ay object lazm el hight we el width bta3 el object ykon akbr mn el values dy \n",
    "        validar_contorno = (w >= ww) and (h >= hh)\n",
    "        if not validar_contorno:\n",
    "            continue \n",
    "\n",
    "        cv2.rectangle(frame1,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        # to get center of object\n",
    "        center = object_center(x,y,w,h)\n",
    "        detect.append(center)\n",
    "        cv2.circle(frame1,center,4,(0,0,255),-1)\n",
    "    \n",
    "    # loop 3shan lma el object yd5ol zone mo3yn a3ml increase ll counter >> 1\n",
    "    for (x,y) in detect:\n",
    "        if (y < (y1+offset)) and  (y > (y1-offset)):\n",
    "            carros+=1\n",
    "            cv2.line(frame1,(25,y1),(1200,y1),(0,0,255),2) \n",
    "            detect.remove((x,y))\n",
    "            print(\"No. of cars detected : \"+str(carros))\n",
    "\n",
    "\n",
    "    cv2.putText(frame1,\"VEHICLE COUNT : \" + str(carros) , (320,70) , cv2.FONT_HERSHEY_COMPLEX , 2 , (0,0,255), 4)\n",
    "    cv2.imshow(\"video Original\",frame1)\n",
    "    cv2.imshow(\"dilat\",dilat)\n",
    "    cv2.imshow(\"img_sub\",img_sub)\n",
    "\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
